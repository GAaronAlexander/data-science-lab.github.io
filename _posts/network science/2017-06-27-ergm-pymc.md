---
layout: single
title: "Estimating ERGM using PyMC"
header:
  teaser: "/assets/images/unsplash-gallery-image-2-th.jpg"
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: /assets/images/unsplash-image-15.jpg
  cta_label: "Read More"
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
excerpt: "This post aims to analyzing the Grey's Anatomy hookup network with ERGMs using PyMC."
modified: 2017-06-21 19:49:48
comments: true
author: ""
tags:
  - ergm
  - python
---




**Author**: David Masad

Source: [https://gist.github.com/dmasad/78cb940de103edbee699](https://gist.github.com/dmasad/78cb940de103edbee699)


This is really a mashup of two tutorials:

1. Benjamin Lind's [ERGM tutorial using the Grey's Anatomy hookup network](http://badhessian.org/2012/09/lessons-on-exponential-random-graph-modeling-from-greys-anatomy-hook-ups/),
2. and this [tutorial on ERGMs using PyMC](http://socialabstractions-blog.tumblr.com/post/53391947460/exponential-random-graph-models-in-python).

Mostly, I wanted to work through the latter tutorial with a different dataset, to make sure I understood what was going on. I'm sharing this in case anyone else finds it useful.

For a more detailed explanation of ERGMs, check out both of the tutorials linked above, or my own tutorial on [implementing ERGMs from scratch in Python](http://davidmasad.com/blog/ergms-from-scratch/) (the end of that has a good roundup of papers for further reading).

For more information on PyMC, you might also want to check out the excellent free handbook [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers) by Cam Davidson-Pilon.

```python
import numpy as np
import networkx as nx
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
from scipy.misc import comb
from itertools import product
import pymc
```


# Loading the data
Unfortunately, the data from the original Grey's Anatomy tutorial seems to be offline. Fortunately, it was preserved on GitHub by [Alex Leavitt and Joshua Clark](https://github.com/alexleavitt/SNAinRworkshop).

The data comes in two tables: the adjacency table gives us the graph itself, and a node attribute table gives us node-level information on each character. Below, I'm going to load both into NetworkX.

## Loading the adjacency table

NetworkX doesn't have a native loader for an adjacency matrix with row and column headers, so here's some code to load it manually.

First, we get the top row; this tell us how many nodes there are, and will be useful for labeling them.


```python
import pandas as pd
```


```python
df = pd.read_csv('../data/grey_adjacency.tsv', sep = '\t', index_col = 0)
df.iloc[:5, :5]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>addison</th>
      <th>adele</th>
      <th>altman</th>
      <th>amelia</th>
      <th>arizona</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>addison</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>adele</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>altman</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>amelia</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>arizona</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
adj = df.as_matrix()
```


```python
G = nx.from_numpy_matrix(adj)
G = nx.relabel_nodes(G, {i: df.index[i] for i in range(44)})
```


# Loading attributes
The attribute data is in a nice, conventional table: each row is a character, and each column is a character attribute. (See the original tutorial for more information on where this data comes from).
Using Python's built-in csv module, we can read in all the rows as dictionaries, which makes it easy to assign the attributes to the network.


```python
df_nodes = pd.read_csv('../data/grey_nodes.tsv', sep = '\t')
df_nodes.iloc[:5,]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>sex</th>
      <th>race</th>
      <th>birthyear</th>
      <th>position</th>
      <th>season</th>
      <th>sign</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>addison</td>
      <td>F</td>
      <td>White</td>
      <td>1967</td>
      <td>Attending</td>
      <td>1</td>
      <td>Libra</td>
    </tr>
    <tr>
      <th>1</th>
      <td>adele</td>
      <td>F</td>
      <td>Black</td>
      <td>1949</td>
      <td>Non-Staff</td>
      <td>2</td>
      <td>Leo</td>
    </tr>
    <tr>
      <th>2</th>
      <td>altman</td>
      <td>F</td>
      <td>White</td>
      <td>1969</td>
      <td>Attending</td>
      <td>6</td>
      <td>Pisces</td>
    </tr>
    <tr>
      <th>3</th>
      <td>amelia</td>
      <td>F</td>
      <td>White</td>
      <td>1981</td>
      <td>Attending</td>
      <td>7</td>
      <td>Libra</td>
    </tr>
    <tr>
      <th>4</th>
      <td>arizona</td>
      <td>F</td>
      <td>White</td>
      <td>1976</td>
      <td>Attending</td>
      <td>5</td>
      <td>Leo</td>
    </tr>
  </tbody>
</table>
</div>




```python
node_attributes = []
for i in df_nodes.index:
    node_attributes.append(df_nodes.iloc[i].to_dict())
```


```python
node_attributes[0]
```




    {'birthyear': 1967,
     'name': 'addison',
     'position': 'Attending',
     'race': 'White',
     'season': 1,
     'sex': 'F',
     'sign': 'Libra'}



Assign the attributes to each node, which are now keyed on the character names:


```python
for node in node_attributes:
    name = node["name"]
    for key, val in node.items():
        if key == "name":
            continue
        G.node[name][key] = val
```

# Drawing the hookup graph
Now that we have the data loaded in, we can draw the hookup graph. I color the male characters in blue and the female characters in pink (because gender norms).


```python
colors = {"M": "mediumslateblue",
          "F": "hotpink"}
node_colors = [colors[node[1]["sex"]] for node in G.nodes(data=True)]
pos = nx.spring_layout(G, k=0.075, scale=4)
```


```python
fig, ax = plt.subplots(figsize=(10, 10))
nx.draw_networkx_nodes(G, pos, node_size=100, node_color=node_colors, ax=ax)
nx.draw_networkx_edges(G, pos, alpha=0.5, ax=ax)
nx.draw_networkx_labels(G, pos, ax=ax)
plt.axis('off')
plt.show()
```


![]({{ site.url }}{{ site.baseurl }}/assets/img2017/pymc0.png)


# Building the ERGM
Now comes the important part: building and fitting the ERGM with **PyMC**.

To start with, we need to know what model we're actually fitting. I use the simplest one, explaining the network in terms of the number of edges and whether those edges are between nodes with the same gender.

We need two NxN matrices, one for each network statistic. Each cell in each matrix indicates how the presence of that potential edge would change that statistic, holding the rest of the network constant.

For the edge count, the matrix is just all 1s -- since any new edge, by definition, increases the edge count by 1.
Gender matching is a specific example of attribute matching: we want a matrix $M$ such that $m_{i,j}=1$ if nodes $i$ and $j$ have the same attribute value (e.g. their gender), and otherwise $0$.

Now, here's one change we make here from the Social Abstractions tutorial. Unlike the prison friendship network, the hookup graph is undirected -- if $i$ has hooked up with $j$, then $j$ has obviously also hooked up with $i$. That means we really need only one half of each matrix, either the upper or lower triangle. We can zero out the other triangle, to make sure that we can only realize one edge per dyad.


```python
def edge_count(G):
    size = len(G)
    ones = np.ones((size, size))
    # Zero out the upper triangle:
    if not G.is_directed():
        ones[np.triu_indices_from(ones)] = 0
    return ones
```


```python
def node_match(G, attrib):
    size = len(G)
    attribs = [node[1][attrib] for node in G.nodes(data=True)]
    match = np.zeros(shape=(size, size))
    for i in range(size):
        for j in range(size):
            if i != j and attribs[i] == attribs[j]:
                match[i,j] = 1
    if not G.is_directed():
        match[np.triu_indices_from(match)] = 0
    return match

```


```python
# Create the gender-match matrix
gender_match_mat = node_match(G, "sex")
```

Now we bring in PyMC stochastic variables for the coefficients on both statistics matrices. The prior for them can be pretty arbitrary, but we want them to be able to take on any value, either positive or negative, and be centered on 0. So, normal distributions it is.

The actual term for each statistic is the coefficient times the matrix; since these values are wholly dependent on stochastic variables, they are PyMC deterministic variables themselves.


```python
density_coef = pymc.Normal("density", 0, 0.001)
gender_match_coef = pymc.Normal("gender_match", 0, 0.001)

density_term = density_coef * edge_count(G)
gender_match_term = gender_match_coef * gender_match_mat
```


```python
term_list = [density_term, gender_match_term]
```

Next, we create the probability matrix, where $p_{i,j}$ is the probability of an edge between $i$ and $j$. This is another PyMC deterministic variable, since the probability is based on the two terms defined above.

We set the upper triangle to 0 here, so that there is only one probability associated with each dyad.


```python
@pymc.deterministic
def probs(term_list=term_list):
    probs = 1/(1+np.exp(-1*sum(term_list))) # The logistic function
    probs[np.diag_indices_from(probs)] = 0
    # Manually cut off the top triangle:
    probs[np.triu_indices_from(probs)] = 0
    return probs
```

Finally, we create the outcome variable: it's a matrix of Bernoulli random values, one for each potential edge, each realized with probability as determined by our mode. This matrix is actually observed as the network's adjacency matrix. It's this outcome that PyMC will maximize the probability of the model generating.



```python
# Get the adjacency matrix, and zero out the upper triangle
matrix = nx.to_numpy_matrix(G)
matrix[np.triu_indices_from(matrix)] = 0
```


```python
outcome = pymc.Bernoulli("outcome", probs, value=matrix, observed=True)
```

In order to view sample networks drawn from the posterior distribution, I add one more random variable: a simulated outcome. This takes the same form as the outcome matrix above, but isn't set as observed. Instead, the value of each potential edge will be randomly drawn based on the probs matrix.


```python
sim_outcome = pymc.Bernoulli("sim_outcome", probs)
```

# Fitting the model

With all the variables finally set, we can plug them all into a model object, and start the MCMC process.


```python
model = pymc.Model([outcome, sim_outcome, probs,
                    density_coef, density_term,
                    gender_match_coef, gender_match_term])
```


```python
mcmc = pymc.MCMC(model)
mcmc.sample(50000, 1000, 50)
```

     [-----------------100%-----------------] 50000 of 50000 complete in 29.3 sec

The estimated coefficients and standard errors are computed from the traces:



```python
density_trace = mcmc.trace("density")[:]
gender_match_trace = mcmc.trace("gender_match")[:]

print("Density: {0:.3f}, {1:.3f}".format(np.mean(density_trace), np.std(density_trace)))
print("Gender: {0:.3f}, {1:.3f}".format(np.mean(gender_match_trace), np.std(gender_match_trace)))
```

    Density: -2.307, 0.156
    Gender: -3.372, 0.847


These are pretty close to the coefficients and standard errors computed in R, suggesting that the model was specified and fit correctly.

# Diagnostics

The R ergm package can plot some diagnostic charts automatically, to help us make sure the model is not degenerate and that chain is mixing well. I plot similar charts below:


```python
fig = plt.figure(figsize=(12,6))
ax1 = fig.add_subplot(221)
ax1.plot(density_trace)
ax1.set_title("Density")
ax2 = fig.add_subplot(222)
ax2.hist(density_trace)
ax2.set_title("Density")

ax3 = fig.add_subplot(223)
ax3.plot(gender_match_trace)
ax3.set_title("Gender_Match")
ax4 = fig.add_subplot(224)
ax4.hist(gender_match_trace)
ax4.set_title("Gender_Match")
plt.show()
```


![]({{ site.url }}{{ site.baseurl }}/assets/img2017/pymc1.png)


# Checking the goodness-of-fit

One way to inspect the goodness-of-fit of the model is to take a random realization of the network from the posterior distribution, and see how it compares to the observed network. This is one of the things we can do with the sim_outcome variable we added to the model.


```python
realization = mcmc.trace("sim_outcome")[-1] # Take the last one

```

Or you can fix the coefficients and draw at random:



```python
# density_coef.value = np.mean(density_trace)
# gender_match_coef.value = np.mean(gender_match_trace)
#realization = sim_outcome.random()
```

Convert the realized matrix to a full network, and add the node attributes:



```python
sim_g = nx.from_numpy_matrix(realization)

sim_g = nx.relabel_nodes(sim_g, {i: df.index[i] for i in range(44)})
for node in node_attributes:
    name = node["name"]
    for key, val in node.items():
        if key == "name":
            continue
        sim_g.node[name][key] = val
```

And visualize. We don't care about the individuals here, since our model was only looking at the gender matching:



```python

colors = {"M": "mediumslateblue",
          "F": "hotpink"}
node_colors = [colors[node[1]["sex"]] for node in sim_g.nodes(data=True)]

pos = nx.spring_layout(sim_g, k=0.075, scale=4)
fig, ax = plt.subplots(figsize=(10, 10))
nx.draw_networkx_nodes(sim_g, pos, node_size=100, node_color=node_colors, ax=ax)
nx.draw_networkx_edges(sim_g, pos, alpha=0.5, ax=ax)
#nx.draw_networkx_labels(sim_g, pos, ax=ax)

_ = ax.axis('off')
```


![]({{ site.url }}{{ site.baseurl }}/assets/img2017/pymc2.png)


This graph looks 'about right' (a really scientific assessment), and the model seems to be capturing a lot of the tendency towards heterosexual pairings (though there appear to be more same-sex pairs, and especially pairs of women, than observed in the actual data). There are also more singletons than observed in the actual data -- though about as many as produced by the R model.

# Degree distribution

Another way of assessing the goodness-of-fit is comparing the degree distribution of the simulated networks to the observed one. The R ergm package has that built in, but here we have to do it ourselves.

To do it, we count the number of nodes of each degree in the observed network, and across all of the simulated networks, and plot them together.


```python
from collections import defaultdict, Counter

```


Observed degree distribution:


```python

obs_deg_freq = Counter(nx.degree(G).values())
x = list(obs_deg_freq.keys())
y = list(obs_deg_freq.values())

```


Simulated degree distributions:


```python
deg_freq = defaultdict(list)
# We don't care about node properties here, just the degree.
for realization in mcmc.trace("sim_outcome")[:]:
    sim_g = nx.from_numpy_matrix(realization)
    for deg, count in Counter(nx.degree(sim_g).values()).items():
        deg_freq[deg].append(count)

vals = list(deg_freq.values())
labels = list(deg_freq.keys())
```

And finally, plot: black dots for the observed degree count, box-and-whiskers plots for the distributions.



```python
fig, ax = plt.subplots()

h = ax.boxplot(vals, positions=labels)
ax.scatter(x, y, s=40)
ax.set_xlim(-1, 10.5)
ax.set_ylim(0, 30)
ax.set_xticklabels(labels)
ax.set_xlabel("$Degree$", fontsize = 20)
ax.set_ylabel("$Frequency$", fontsize = 20)
ax.set_title("Degree distribution\nObserved vs Simulated", fontsize = 20)

plt.show()
```


![]({{ site.url }}{{ site.baseurl }}/assets/img2017/pymc3.png)
